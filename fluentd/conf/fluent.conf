# bind fluentd on IP 0.0.0.0
# port 24224
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# parse JSON payload from 'log' field and merge into record
# but skip parsing for error logs to avoid mapping conflicts
<filter **>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

# Handle error logs separately to avoid mapping conflicts
<filter fluent.error>
  @type record_transformer
  <record>
    error_message ${record["message"]}
  </record>
</filter>



# sendlog to the elasticsearch
# the host must match to the elasticsearch
# container service
<match *.**>
  @type copy
  <store>
    @type elasticsearch_dynamic
    hosts elasticsearch:9200
    user elastic
    password elastic
    logstash_format true
    logstash_prefix fluentd
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    include_timestamp true
    flush_interval 30s
  </store>
  <store>
    @type stdout
  </store>
</match>
